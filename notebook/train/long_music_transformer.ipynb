{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Train Music Transformer\n",
    "Since Fri. Feb. 25th, 2022\n",
    "\n",
    "Set up training in colab\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "\n",
    "### Ipython\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Colab\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| PATH_BASE: '/Users/stefanh/Documents/UMich/Research/Music with NLP'\n",
      "    DIR_PROJ: 'Symbolic-Music-Generation'\n",
      "    PKG_NM: 'musicnlp'\n"
     ]
    },
    {
     "data": {
      "text/plain": "('/Users/stefanh/Documents/UMich/Research/Music with NLP',\n 'Symbolic-Music-Generation',\n 'musicnlp')"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    ! pip3 install sty icecream music21 transformers datasets==1.18.3  # for `set_progress_bar_enabled`\n",
    "\n",
    "    path = os.path.join('drive', 'My Drive', 'Research', 'Music with NLP', 'Symbolic-Music-Generation')\n",
    "    sys.path.append(path)\n",
    "    ! ls \"{path}\"\n",
    "\n",
    "\n",
    "    import time, os\n",
    "    os.environ['TZ'] = 'US/Eastern'\n",
    "    time.tzset()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        %env PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    ! nvidia-smi\n",
    "\n",
    "\n",
    "from icecream import ic\n",
    "\n",
    "from musicnlp.util import *\n",
    "\n",
    "ic(PATH_BASE, DIR_PROJ, PKG_NM)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from musicnlp.util import *\n",
    "from musicnlp.models import train\n",
    "\n",
    "\n",
    "seed = config('random-seed')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prep for training\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/processed/musicnlp music extraction, dnm=POP909, n=909, meta={mode=melody, prec=5, th=1}, 2022-04-10_12-51-01/train/cache-0ade476f1b4e9e0c.arrow\n",
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/processed/musicnlp music extraction, dnm=POP909, n=909, meta={mode=melody, prec=5, th=1}, 2022-04-10_12-51-01/train/cache-5d57d94a1bfb3813.arrow\n",
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/processed/musicnlp music extraction, dnm=POP909, n=909, meta={mode=melody, prec=5, th=1}, 2022-04-10_12-51-01/train/cache-ae59fc2f8b1b097f.arrow\n",
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/processed/musicnlp music extraction, dnm=POP909, n=909, meta={mode=melody, prec=5, th=1}, 2022-04-10_12-51-01/train/cache-6ef30963ee279abe.arrow\n",
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/processed/musicnlp music extraction, dnm=POP909, n=909, meta={mode=melody, prec=5, th=1}, 2022-04-10_12-51-01/train/cache-38b44488c8e09217.arrow\n",
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/processed/musicnlp music extraction, dnm=POP909, n=909, meta={mode=melody, prec=5, th=1}, 2022-04-10_12-51-01/train/cache-480823f81b28ab7c.arrow\n",
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/processed/musicnlp music extraction, dnm=POP909, n=909, meta={mode=melody, prec=5, th=1}, 2022-04-10_12-51-01/train/cache-b1980c60777774ab.arrow\n",
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/processed/musicnlp music extraction, dnm=POP909, n=909, meta={mode=melody, prec=5, th=1}, 2022-04-10_12-51-01/train/cache-a4c2e5cf9b0a3da6.arrow\n",
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/processed/musicnlp music extraction, dnm=POP909, n=909, meta={mode=melody, prec=5, th=1}, 2022-04-10_12-51-01/test/cache-c901796289dcb331.arrow\n",
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/processed/musicnlp music extraction, dnm=POP909, n=909, meta={mode=melody, prec=5, th=1}, 2022-04-10_12-51-01/test/cache-f7ad5eddbb5e5f73.arrow\n",
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/processed/musicnlp music extraction, dnm=POP909, n=909, meta={mode=melody, prec=5, th=1}, 2022-04-10_12-51-01/test/cache-35d65bc7c035ba9d.arrow\n",
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/processed/musicnlp music extraction, dnm=POP909, n=909, meta={mode=melody, prec=5, th=1}, 2022-04-10_12-51-01/test/cache-2d5be7246ab5b1ca.arrow\n",
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/processed/musicnlp music extraction, dnm=POP909, n=909, meta={mode=melody, prec=5, th=1}, 2022-04-10_12-51-01/test/cache-b89fa1a8a2324f63.arrow\n",
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/processed/musicnlp music extraction, dnm=POP909, n=909, meta={mode=melody, prec=5, th=1}, 2022-04-10_12-51-01/test/cache-073279bb2c16df21.arrow\n",
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/processed/musicnlp music extraction, dnm=POP909, n=909, meta={mode=melody, prec=5, th=1}, 2022-04-10_12-51-01/test/cache-e9d3d75ffe6f7f99.arrow\n",
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/processed/musicnlp music extraction, dnm=POP909, n=909, meta={mode=melody, prec=5, th=1}, 2022-04-10_12-51-01/test/cache-5012178000defe5a.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/processed/musicnlp music extraction, dnm=POP909, n=909, meta={mode=melody, prec=5, th=1}, 2022-04-10_12-51-01/train/cache-dfdc3593ad1117f2.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/processed/musicnlp music extraction, dnm=POP909, n=909, meta={mode=melody, prec=5, th=1}, 2022-04-10_12-51-01/test/cache-4d42c59cec2e95df.arrow\n"
     ]
    }
   ],
   "source": [
    "dnm_909 = 'musicnlp music extraction, dnm=POP909, n=909, meta={mode=melody, prec=5, th=1}, 2022-04-10_12-51-01'\n",
    "dnm_lmd = 'musicnlp music extraction, dnm=LMD-cleaned-subset, ' \\\n",
    "          'n=10269, meta={mode=melody, prec=5, th=1}, 2022-04-10_12-52-41'\n",
    "dnms = [dnm_909, dnm_lmd]\n",
    "\n",
    "md_nm = 'reformer'\n",
    "md_sz = 'tiny'\n",
    "# md_sz = 'base'\n",
    "\n",
    "\n",
    "if md_nm != 'reformer':\n",
    "    import transformers\n",
    "    transformers.set_seed(seed)\n",
    "\n",
    "\n",
    "if md_sz in ['debug', 'tiny']:  # debugging\n",
    "    n = 8\n",
    "    train_args = dict(\n",
    "        per_device_train_batch_size=4,\n",
    "        # save_strategy='no',\n",
    "        save_strategy='epoch',\n",
    "        num_train_epochs=64,\n",
    "    )\n",
    "    my_train_args = dict(\n",
    "        save_epochs=16\n",
    "    )\n",
    "else:\n",
    "    n = None\n",
    "    train_args = dict(num_train_epochs=16)\n",
    "    my_train_args = dict(\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        logging_strategy='epoch',\n",
    "        save_epochs=4\n",
    "    )\n",
    "\n",
    "mdl, tokenizer, trainer = train.get_all_setup(\n",
    "    model_name=md_nm, model_size=md_sz, dataset_names=dnms, n_sample=n, dataset_seed=seed,\n",
    "    train_args=train_args, my_train_args=my_train_args\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;2;0;186;142m2022-04-10 16:48:26\u001B[38;2;97;175;239m|\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[ReformerModelWithLMHead Training]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mon_train_begin\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m180\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mTraining started with model \u001B[35m{\u001B[39m\u001B[49m\u001B[0mmodel name: \u001B[34mReformerModelWithLMHead\u001B[39m\u001B[49m\u001B[0m, max length: \u001B[34m1024\u001B[39m\u001B[49m\u001B[0m, axial_pos_shape: \u001B[34m(32, 32)\u001B[39m\u001B[49m\u001B[0m, n_layer: \u001B[34m6\u001B[39m\u001B[49m\u001B[0m, hidden_size: \u001B[34m256\u001B[39m\u001B[49m\u001B[0m, ff_size: \u001B[34m1024\u001B[39m\u001B[49m\u001B[0m, attention_shape: \u001B[34m8x32\u001B[39m\u001B[49m\u001B[0m, parameter_count: \u001B[34m4.6M\u001B[39m\u001B[49m\u001B[0m\u001B[35m}\u001B[39m\u001B[49m\u001B[0m, {\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"hash_seed\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"vocab_size\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m390\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"attention_head_size\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m32\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"hidden_size\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m256\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"num_attention_heads\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m8\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"num_hashes\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m1\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"num_hidden_layers\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m6\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"num_buckets\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"lsh_attn_chunk_length\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m64\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"local_attn_chunk_length\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m64\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"lsh_num_chunks_after\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m0\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"lsh_num_chunks_before\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m1\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"local_num_chunks_after\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m0\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"local_num_chunks_before\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m1\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"hidden_act\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[33m\"relu\"\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"feed_forward_size\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m1024\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"hidden_dropout_prob\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m0.05\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"lsh_attention_probs_dropout_prob\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m0.0\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"local_attention_probs_dropout_prob\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m0.05\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"max_position_embeddings\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m1024\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"initializer_range\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m0.02\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"layer_norm_eps\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m1e-12\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"axial_pos_embds\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mtrue\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"axial_pos_shape\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m[\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m        \u001B[39;49;00m\u001B[34m32\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m        \u001B[39;49;00m\u001B[34m32\u001B[39;49;00m\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m],\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"axial_pos_embds_dim\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m[\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m        \u001B[39;49;00m\u001B[34m64\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m        \u001B[39;49;00m\u001B[34m192\u001B[39;49;00m\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m],\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"axial_norm_std\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m1.0\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"chunk_size_lm_head\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m0\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"attn_layers\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m[\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m        \u001B[39;49;00m\u001B[33m\"local\"\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m        \u001B[39;49;00m\u001B[33m\"lsh\"\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m        \u001B[39;49;00m\u001B[33m\"local\"\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m        \u001B[39;49;00m\u001B[33m\"lsh\"\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m        \u001B[39;49;00m\u001B[33m\"local\"\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m        \u001B[39;49;00m\u001B[33m\"lsh\"\u001B[39;49;00m\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m],\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"use_cache\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mtrue\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"classifier_dropout\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"return_dict\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mtrue\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"output_hidden_states\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"output_attentions\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"torchscript\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"torch_dtype\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"use_bfloat16\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"pruned_heads\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m{},\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"tie_word_embeddings\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"is_encoder_decoder\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"is_decoder\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mtrue\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"cross_attention_hidden_size\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"add_cross_attention\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"tie_encoder_decoder\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"max_length\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m20\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"min_length\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m0\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"do_sample\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"early_stopping\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"num_beams\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m1\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"num_beam_groups\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m1\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"diversity_penalty\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m0.0\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"temperature\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m1.0\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"top_k\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m50\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"top_p\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m1.0\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"repetition_penalty\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m1.0\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"length_penalty\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m1.0\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"no_repeat_ngram_size\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m0\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"encoder_no_repeat_ngram_size\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m0\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"bad_words_ids\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"num_return_sequences\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m1\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"chunk_size_feed_forward\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m0\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"output_scores\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"return_dict_in_generate\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"forced_bos_token_id\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"forced_eos_token_id\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"remove_invalid_values\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"architectures\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"finetuning_task\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"id2label\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m{\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m        \u001B[39;49;00m\u001B[94m\"0\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[33m\"LABEL_0\"\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m        \u001B[39;49;00m\u001B[94m\"1\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[33m\"LABEL_1\"\u001B[39;49;00m\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m},\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"label2id\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m{\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m        \u001B[39;49;00m\u001B[94m\"LABEL_0\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m0\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m        \u001B[39;49;00m\u001B[94m\"LABEL_1\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m1\u001B[39;49;00m\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m},\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"tokenizer_class\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"prefix\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"bos_token_id\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"pad_token_id\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m389\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"eos_token_id\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m0\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"sep_token_id\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"decoder_start_token_id\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"task_specific_params\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"problem_type\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"_name_or_path\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[33m\"\"\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"transformers_version\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[33m\"4.16.2\"\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"model_type\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[33m\"reformer\"\u001B[39;49;00m\u001B[37m\u001B[39;49;00m\n",
      "}\u001B[37m\u001B[39;49;00m\n",
      " on \u001B[35m{\u001B[39m\u001B[49m\u001B[0m#data: \u001B[34m8\u001B[39m\u001B[49m\u001B[0m, batch shape: \u001B[34m(4, 1024)\u001B[39m\u001B[49m\u001B[0m, #epochs: \u001B[34m64\u001B[39m\u001B[49m\u001B[0m, #steps: \u001B[34m128\u001B[39m\u001B[49m\u001B[0m, learning rate: \u001B[34m0.0003\u001B[39m\u001B[49m\u001B[0m\u001B[35m}\u001B[39m\u001B[49m\u001B[0m with training args {\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"output_dir\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[33m\"/Users/stefanh/Documents/UMich/Research/Music with NLP/Symbolic-Music-Generation/models/reformer/2022-04-10_16-48-25\"\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"overwrite_output_dir\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"do_train\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mtrue\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"do_eval\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mtrue\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"do_predict\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"evaluation_strategy\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[33m\"epoch\"\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"prediction_loss_only\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"per_device_train_batch_size\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m4\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"per_device_eval_batch_size\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m32\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"per_gpu_train_batch_size\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"per_gpu_eval_batch_size\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"gradient_accumulation_steps\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m1\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"eval_accumulation_steps\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m1\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"learning_rate\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m0.0003\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"weight_decay\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m0.01\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"adam_beta1\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m0.9\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"adam_beta2\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m0.999\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"adam_epsilon\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m1e-08\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"max_grad_norm\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m1\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"num_train_epochs\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m64\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"max_steps\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m-1\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"lr_scheduler_type\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[33m\"cosine\"\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"warmup_ratio\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m0.1\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"warmup_steps\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m0\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"log_level\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m30\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"log_level_replica\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m-1\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"log_on_each_node\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mtrue\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"logging_dir\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[33m\"/Users/stefanh/Documents/UMich/Research/Music with NLP/Symbolic-Music-Generation/models/reformer/2022-04-10_16-48-25/runs/Apr10_16-48-25_Ma-Big-Mac\"\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"logging_strategy\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[33m\"steps\"\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"logging_first_step\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"logging_steps\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m1\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"logging_nan_inf_filter\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mtrue\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"save_strategy\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[33m\"steps\"\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"save_steps\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m32\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"save_total_limit\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"save_on_each_node\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"no_cuda\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"seed\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m42\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"bf16\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"fp16\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"fp16_opt_level\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[33m\"O1\"\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"half_precision_backend\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[33m\"auto\"\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"bf16_full_eval\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"fp16_full_eval\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"tf32\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"local_rank\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m-1\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"xpu_backend\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"tpu_num_cores\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"tpu_metrics_debug\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"debug\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m[],\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"dataloader_drop_last\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"eval_steps\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"dataloader_num_workers\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m0\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"past_index\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m-1\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"run_name\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[33m\"/Users/stefanh/Documents/UMich/Research/Music with NLP/Symbolic-Music-Generation/models/reformer/2022-04-10_16-48-25\"\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"disable_tqdm\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mtrue\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"remove_unused_columns\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mtrue\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"label_names\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"load_best_model_at_end\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"metric_for_best_model\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"greater_is_better\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"ignore_data_skip\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"sharded_ddp\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m[],\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"deepspeed\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"label_smoothing_factor\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m0.0\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"optim\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[33m\"adamw_torch\"\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"adafactor\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"group_by_length\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"length_column_name\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[33m\"length\"\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"report_to\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m[],\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"ddp_find_unused_parameters\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"ddp_bucket_cap_mb\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"dataloader_pin_memory\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mtrue\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"skip_memory_metrics\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mtrue\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"use_legacy_prediction_loop\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"push_to_hub\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"resume_from_checkpoint\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"hub_model_id\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"hub_strategy\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[33m\"every_save\"\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"hub_token\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[33m\"<HUB_TOKEN>\"\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"gradient_checkpointing\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mfalse\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"fp16_backend\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[33m\"auto\"\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"push_to_hub_model_id\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"push_to_hub_organization\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mnull\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"push_to_hub_token\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[33m\"<PUSH_TO_HUB_TOKEN>\"\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"_n_gpu\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m0\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[94m\"mp_parameters\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[33m\"\"\u001B[39;49;00m\u001B[37m\u001B[39;49;00m\n",
      "}\u001B[37m\u001B[39;49;00m\n",
      " and my training args \u001B[35m{\u001B[39m\u001B[49m\u001B[0mlogging_strategy: \u001B[34msteps\u001B[39m\u001B[49m\u001B[0m, save_epochs: \u001B[34m16\u001B[39m\u001B[49m\u001B[0m, steps_per_epoch: \u001B[34m2\u001B[39m\u001B[49m\u001B[0m\u001B[35m}\u001B[39m\u001B[49m\u001B[0m... \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.num_buckets is not set. Setting config.num_buckets to 32...\n",
      "config.num_buckets is not set. Setting config.num_buckets to 32...\n",
      "config.num_buckets is not set. Setting config.num_buckets to 32...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;2;0;186;142m2022-04-10 16:48:29\u001B[38;2;97;175;239m|\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[ReformerModelWithLMHead Training]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221m_log\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m249\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[35m{\u001B[39m\u001B[49m\u001B[0mstep: \u001B[34m  1/128\u001B[39m\u001B[49m\u001B[0m, epoch: \u001B[34m 0.500/64\u001B[39m\u001B[49m\u001B[0m, train/learning_rate: \u001B[34m2.310e-05\u001B[39m\u001B[49m\u001B[0m, train/loss: \u001B[34m6.0604\u001B[39m\u001B[49m\u001B[0m, train/ntp_acc: \u001B[34m 0.17\u001B[39m\u001B[49m\u001B[0m, train/ikr: \u001B[34m 9.57\u001B[39m\u001B[49m\u001B[0m\u001B[35m}\u001B[39m\u001B[49m\u001B[0m\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n",
      "\u001B[38;2;0;186;142m2022-04-10 16:48:33\u001B[38;2;97;175;239m|\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[ReformerModelWithLMHead Training]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221m_log\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m249\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[35m{\u001B[39m\u001B[49m\u001B[0mstep: \u001B[34m  2/128\u001B[39m\u001B[49m\u001B[0m, epoch: \u001B[34m 1.000/64\u001B[39m\u001B[49m\u001B[0m, train/learning_rate: \u001B[34m4.620e-05\u001B[39m\u001B[49m\u001B[0m, train/loss: \u001B[34m6.0626\u001B[39m\u001B[49m\u001B[0m, train/ntp_acc: \u001B[34m 0.12\u001B[39m\u001B[49m\u001B[0m, train/ikr: \u001B[34m12.46\u001B[39m\u001B[49m\u001B[0m\u001B[35m}\u001B[39m\u001B[49m\u001B[0m\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n",
      "\u001B[38;2;0;186;142m2022-04-10 16:48:35\u001B[38;2;97;175;239m|\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[ReformerModelWithLMHead Training]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221m_log\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m249\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[35m{\u001B[39m\u001B[49m\u001B[0mstep: \u001B[34m  2/128\u001B[39m\u001B[49m\u001B[0m, epoch: \u001B[34m 1/64\u001B[39m\u001B[49m\u001B[0m, eval/loss: \u001B[34m6.0068\u001B[39m\u001B[49m\u001B[0m, eval/ntp_acc: \u001B[34m 0.21\u001B[39m\u001B[49m\u001B[0m, eval/ikr: \u001B[34m 9.44\u001B[39m\u001B[49m\u001B[0m\u001B[35m}\u001B[39m\u001B[49m\u001B[0m\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n",
      "\u001B[38;2;0;186;142m2022-04-10 16:48:38\u001B[38;2;97;175;239m|\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[ReformerModelWithLMHead Training]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221m_log\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m249\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[35m{\u001B[39m\u001B[49m\u001B[0mstep: \u001B[34m  3/128\u001B[39m\u001B[49m\u001B[0m, epoch: \u001B[34m 1.500/64\u001B[39m\u001B[49m\u001B[0m, train/learning_rate: \u001B[34m6.920e-05\u001B[39m\u001B[49m\u001B[0m, train/loss: \u001B[34m 6.01\u001B[39m\u001B[49m\u001B[0m, train/ntp_acc: \u001B[34m 0.39\u001B[39m\u001B[49m\u001B[0m, train/ikr: \u001B[34m12.12\u001B[39m\u001B[49m\u001B[0m\u001B[35m}\u001B[39m\u001B[49m\u001B[0m\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/76/fm8fgr4n1p78whqg7x_bd5480000gn/T/ipykernel_11002/2578497317.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moutput_dir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'trained'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/transformers/trainer.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1363\u001B[0m                         \u001B[0mtr_loss_step\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1364\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1365\u001B[0;31m                     \u001B[0mtr_loss_step\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1366\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1367\u001B[0m                 if (\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/transformers/trainer.py\u001B[0m in \u001B[0;36mtraining_step\u001B[0;34m(self, model, inputs)\u001B[0m\n\u001B[1;32m   1938\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1939\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautocast_smart_context_manager\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1940\u001B[0;31m             \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompute_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1941\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1942\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mn_gpu\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/UMich/Research/Music with NLP/Symbolic-Music-Generation/musicnlp/util/train.py\u001B[0m in \u001B[0;36mcompute_loss\u001B[0;34m(self, model, inputs, return_outputs)\u001B[0m\n\u001B[1;32m     91\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     92\u001B[0m             \u001B[0mlabels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 93\u001B[0;31m         \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     94\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     95\u001B[0m         \u001B[0;31m# ========================== Begin of added ==========================\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/transformers/models/reformer/modeling_reformer.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input_ids, position_ids, attention_mask, head_mask, inputs_embeds, num_hashes, past_buckets_states, use_cache, output_hidden_states, output_attentions, return_dict, labels)\u001B[0m\n\u001B[1;32m   2223\u001B[0m         \u001B[0mreturn_dict\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mreturn_dict\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mreturn_dict\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0muse_return_dict\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2224\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2225\u001B[0;31m         reformer_outputs = self.reformer(\n\u001B[0m\u001B[1;32m   2226\u001B[0m             \u001B[0minput_ids\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2227\u001B[0m             \u001B[0mposition_ids\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mposition_ids\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/transformers/models/reformer/modeling_reformer.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, num_hashes, past_buckets_states, use_cache, output_hidden_states, output_attentions, return_dict)\u001B[0m\n\u001B[1;32m   2083\u001B[0m         )\n\u001B[1;32m   2084\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2085\u001B[0;31m         encoder_outputs = self.encoder(\n\u001B[0m\u001B[1;32m   2086\u001B[0m             \u001B[0mhidden_states\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0membedding_output\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2087\u001B[0m             \u001B[0mhead_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mhead_mask\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/transformers/models/reformer/modeling_reformer.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, hidden_states, attention_mask, head_mask, num_hashes, past_buckets_states, use_cache, orig_sequence_length, output_hidden_states, output_attentions)\u001B[0m\n\u001B[1;32m   1709\u001B[0m         \u001B[0;31m# concat same tensor for reversible ResNet\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1710\u001B[0m         \u001B[0mhidden_states\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mhidden_states\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhidden_states\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1711\u001B[0;31m         hidden_states = _ReversibleFunction.apply(\n\u001B[0m\u001B[1;32m   1712\u001B[0m             \u001B[0mhidden_states\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1713\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/transformers/models/reformer/modeling_reformer.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(ctx, hidden_states, layers, attention_mask, head_mask, num_hashes, all_hidden_states, all_attentions, past_buckets_states, use_cache, orig_sequence_length, output_hidden_states, output_attentions)\u001B[0m\n\u001B[1;32m   1598\u001B[0m                 \u001B[0mall_hidden_states\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhidden_states\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1599\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1600\u001B[0;31m             layer_outputs = layer(\n\u001B[0m\u001B[1;32m   1601\u001B[0m                 \u001B[0mprev_attn_output\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mattn_output\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1602\u001B[0m                 \u001B[0mhidden_states\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mhidden_states\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/transformers/models/reformer/modeling_reformer.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m   1489\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_init_feed_forward_seed\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1490\u001B[0m             \u001B[0;31m# Y_2 = X_2 + g(Y_1)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1491\u001B[0;31m             \u001B[0mhidden_states\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhidden_states\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfeed_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mattn_output\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1492\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1493\u001B[0m         return ReformerOutput(\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/transformers/models/reformer/modeling_reformer.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, attention_output)\u001B[0m\n\u001B[1;32m   1386\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1387\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mattention_output\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1388\u001B[0;31m         return apply_chunking_to_forward(\n\u001B[0m\u001B[1;32m   1389\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward_chunk\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1390\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchunk_size_feed_forward\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/transformers/modeling_utils.py\u001B[0m in \u001B[0;36mapply_chunking_to_forward\u001B[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001B[0m\n\u001B[1;32m   2436\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput_chunks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mchunk_dim\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2437\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2438\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mforward_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput_tensors\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2439\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2440\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/transformers/models/reformer/modeling_reformer.py\u001B[0m in \u001B[0;36mforward_chunk\u001B[0;34m(self, hidden_states)\u001B[0m\n\u001B[1;32m   1395\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward_chunk\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhidden_states\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1396\u001B[0m         \u001B[0mhidden_states\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayer_norm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhidden_states\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1397\u001B[0;31m         \u001B[0mhidden_states\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdense\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhidden_states\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1398\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhidden_states\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1399\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/transformers/models/reformer/modeling_reformer.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, hidden_states)\u001B[0m\n\u001B[1;32m   1356\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1357\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhidden_states\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1358\u001B[0;31m         \u001B[0mhidden_states\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdense\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhidden_states\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1359\u001B[0m         \u001B[0mhidden_states\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunctional\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhidden_states\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mp\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1360\u001B[0m         \u001B[0mhidden_states\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mact_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhidden_states\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    101\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    102\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 103\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    104\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    105\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mextra_repr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/torch/nn/functional.py\u001B[0m in \u001B[0;36mlinear\u001B[0;34m(input, weight, bias)\u001B[0m\n\u001B[1;32m   1846\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mhas_torch_function_variadic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1847\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mhandle_torch_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1848\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_nn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1849\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1850\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(os.path.join(trainer.args.output_dir, 'trained'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check log and tensorboard files written\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ic(trainer.args.output_dir)\n",
    "os.listdir(trainer.args.output_dir)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}