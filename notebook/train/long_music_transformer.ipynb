{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Train Music Transformer\n",
    "Since Fri. Feb. 25th, 2022\n",
    "\n",
    "Set up training in colab\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "\n",
    "### Ipython\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Colab\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/stefanh/Documents/UMich/Research/Music with NLP\n",
      "Symbolic-Music-Generation\n",
      "musicnlp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    ! pip3 install sty icecream music21 transformers datasets\n",
    "\n",
    "    sys.path.append(os.path.join('drive', 'My Drive', 'Research', 'Music with NLP', 'Symbolic-Music-Generation'))\n",
    "\n",
    "\n",
    "from musicnlp.util import *\n",
    "\n",
    "\n",
    "print(PATH_BASE)\n",
    "print(DIR_PROJ)\n",
    "print(PKG_NM)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "from icecream import ic\n",
    "\n",
    "from musicnlp.util import *\n",
    "from musicnlp.model import long_music_transformer as lmt\n",
    "\n",
    "\n",
    "seed = config('random-seed')\n",
    "transformers.set_seed(seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prep for training\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/hf_datasets/musicnlp music extraction, dnm=POP909, n=909, mode=melody, 2022-02-25 20-59-06/cache-f417996c5f50becf.arrow\n",
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/hf_datasets/musicnlp music extraction, dnm=POP909, n=909, mode=melody, 2022-02-25 20-59-06/cache-bdad8eedf3d98cb4.arrow\n",
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/hf_datasets/musicnlp music extraction, dnm=POP909, n=909, mode=melody, 2022-02-25 20-59-06/cache-e6c3ee9dc9d05a25.arrow\n",
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/hf_datasets/musicnlp music extraction, dnm=POP909, n=909, mode=melody, 2022-02-25 20-59-06/cache-47ffba45fbbacb63.arrow\n",
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/hf_datasets/musicnlp music extraction, dnm=POP909, n=909, mode=melody, 2022-02-25 20-59-06/cache-02a376952c146b6a.arrow\n",
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/hf_datasets/musicnlp music extraction, dnm=POP909, n=909, mode=melody, 2022-02-25 20-59-06/cache-001fcd44b318634e.arrow\n",
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/hf_datasets/musicnlp music extraction, dnm=POP909, n=909, mode=melody, 2022-02-25 20-59-06/cache-d1d88773687384b1.arrow\n",
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/hf_datasets/musicnlp music extraction, dnm=POP909, n=909, mode=melody, 2022-02-25 20-59-06/cache-321410a59e6d8d2a.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/hf_datasets/musicnlp music extraction, dnm=POP909, n=909, mode=melody, 2022-02-25 20-59-06/cache-655330db17738fe9.arrow\n",
      "ic| trainer.args.output_dir: ('/Users/stefanh/Documents/UMich/Research/Music with '\n",
      "                              'NLP/Symbolic-Music-Generation/models/debug/2022-02-26 16-22-47')\n"
     ]
    },
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fnm = 'musicnlp music extraction, dnm=POP909, n=909, mode=melody, 2022-02-22 19-00-40'\n",
    "fnm = 'musicnlp music extraction, dnm=POP909, n=909, mode=melody, 2022-02-25 20-59-06'\n",
    "\n",
    "\n",
    "md_nm = 'debug'\n",
    "# md_nm = 'debug-large'\n",
    "\n",
    "n = 4\n",
    "# n = None\n",
    "\n",
    "mdl, tokenizer, dset_tr, trainer = lmt.get_all_setup(model_name=md_nm, dataset_name=fnm, n_sample=n, random_seed=seed)\n",
    "ic(trainer.args.output_dir)\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir tb_log\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;2;0;186;142m2022-02-26 16:22:50\u001B[38;2;97;175;239m| \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[LMTTransformer training]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mon_train_begin\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m146\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mTraining started with \u001B[35m{\u001B[39m\u001B[49m\u001B[0m#data: \u001B[34m909\u001B[39m\u001B[49m\u001B[0m, model size: \u001B[34m8\u001B[39m\u001B[49m\u001B[0m, learning rate: \u001B[34m0.0005\u001B[39m\u001B[49m\u001B[0m, batch shape: \u001B[34m(4, 8)\u001B[39m\u001B[49m\u001B[0m, #epochs: \u001B[34m8\u001B[39m\u001B[49m\u001B[0m, #steps: \u001B[34m1816\u001B[39m\u001B[49m\u001B[0m\u001B[35m}\u001B[39m\u001B[49m\u001B[0m\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n",
      "\u001B[38;2;0;186;142m2022-02-26 16:22:54\u001B[38;2;97;175;239m| \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[LMTTransformer training]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mon_log\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m194\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mstep=\u001B[34m   1\u001B[39m\u001B[49m\u001B[0m, epoch=\u001B[34m  0.00\u001B[39m\u001B[49m\u001B[0m, train_loss=\u001B[34m 9.9020\u001B[39m\u001B[49m\u001B[0m, learning_rate=\u001B[34m5.00e-04\u001B[39m\u001B[49m\u001B[0m\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n",
      "\u001B[38;2;0;186;142m2022-02-26 16:22:57\u001B[38;2;97;175;239m| \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[LMTTransformer training]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mon_log\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m194\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mstep=\u001B[34m   2\u001B[39m\u001B[49m\u001B[0m, epoch=\u001B[34m  0.01\u001B[39m\u001B[49m\u001B[0m, train_loss=\u001B[34m 9.9006\u001B[39m\u001B[49m\u001B[0m, learning_rate=\u001B[34m5.00e-04\u001B[39m\u001B[49m\u001B[0m\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n",
      "\u001B[38;2;0;186;142m2022-02-26 16:23:00\u001B[38;2;97;175;239m| \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[LMTTransformer training]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mon_log\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m194\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mstep=\u001B[34m   3\u001B[39m\u001B[49m\u001B[0m, epoch=\u001B[34m  0.01\u001B[39m\u001B[49m\u001B[0m, train_loss=\u001B[34m 9.8790\u001B[39m\u001B[49m\u001B[0m, learning_rate=\u001B[34m5.00e-04\u001B[39m\u001B[49m\u001B[0m\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n",
      "\u001B[38;2;0;186;142m2022-02-26 16:23:03\u001B[38;2;97;175;239m| \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[LMTTransformer training]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mon_log\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m194\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mstep=\u001B[34m   4\u001B[39m\u001B[49m\u001B[0m, epoch=\u001B[34m  0.02\u001B[39m\u001B[49m\u001B[0m, train_loss=\u001B[34m 9.8650\u001B[39m\u001B[49m\u001B[0m, learning_rate=\u001B[34m5.00e-04\u001B[39m\u001B[49m\u001B[0m\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n",
      "\u001B[38;2;0;186;142m2022-02-26 16:23:06\u001B[38;2;97;175;239m| \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[LMTTransformer training]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mon_log\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m194\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mstep=\u001B[34m   5\u001B[39m\u001B[49m\u001B[0m, epoch=\u001B[34m  0.02\u001B[39m\u001B[49m\u001B[0m, train_loss=\u001B[34m 9.8417\u001B[39m\u001B[49m\u001B[0m, learning_rate=\u001B[34m5.00e-04\u001B[39m\u001B[49m\u001B[0m\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n",
      "\u001B[38;2;0;186;142m2022-02-26 16:23:10\u001B[38;2;97;175;239m| \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[LMTTransformer training]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mon_log\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m194\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mstep=\u001B[34m   6\u001B[39m\u001B[49m\u001B[0m, epoch=\u001B[34m  0.03\u001B[39m\u001B[49m\u001B[0m, train_loss=\u001B[34m 9.8172\u001B[39m\u001B[49m\u001B[0m, learning_rate=\u001B[34m5.00e-04\u001B[39m\u001B[49m\u001B[0m\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n",
      "\u001B[38;2;0;186;142m2022-02-26 16:23:13\u001B[38;2;97;175;239m| \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[LMTTransformer training]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mon_log\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m194\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mstep=\u001B[34m   7\u001B[39m\u001B[49m\u001B[0m, epoch=\u001B[34m  0.03\u001B[39m\u001B[49m\u001B[0m, train_loss=\u001B[34m 9.7759\u001B[39m\u001B[49m\u001B[0m, learning_rate=\u001B[34m5.00e-04\u001B[39m\u001B[49m\u001B[0m\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n",
      "\u001B[38;2;0;186;142m2022-02-26 16:23:16\u001B[38;2;97;175;239m| \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[LMTTransformer training]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mon_log\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m194\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mstep=\u001B[34m   8\u001B[39m\u001B[49m\u001B[0m, epoch=\u001B[34m  0.04\u001B[39m\u001B[49m\u001B[0m, train_loss=\u001B[34m 9.7578\u001B[39m\u001B[49m\u001B[0m, learning_rate=\u001B[34m5.00e-04\u001B[39m\u001B[49m\u001B[0m\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n",
      "\u001B[38;2;0;186;142m2022-02-26 16:23:19\u001B[38;2;97;175;239m| \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[LMTTransformer training]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mon_log\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m194\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mstep=\u001B[34m   9\u001B[39m\u001B[49m\u001B[0m, epoch=\u001B[34m  0.04\u001B[39m\u001B[49m\u001B[0m, train_loss=\u001B[34m 9.7118\u001B[39m\u001B[49m\u001B[0m, learning_rate=\u001B[34m5.00e-04\u001B[39m\u001B[49m\u001B[0m\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n",
      "\u001B[38;2;0;186;142m2022-02-26 16:23:22\u001B[38;2;97;175;239m| \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[LMTTransformer training]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mon_log\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m194\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mstep=\u001B[34m  10\u001B[39m\u001B[49m\u001B[0m, epoch=\u001B[34m  0.04\u001B[39m\u001B[49m\u001B[0m, train_loss=\u001B[34m 9.6824\u001B[39m\u001B[49m\u001B[0m, learning_rate=\u001B[34m5.00e-04\u001B[39m\u001B[49m\u001B[0m\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n",
      "\u001B[38;2;0;186;142m2022-02-26 16:23:26\u001B[38;2;97;175;239m| \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[LMTTransformer training]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mon_log\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m194\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mstep=\u001B[34m  11\u001B[39m\u001B[49m\u001B[0m, epoch=\u001B[34m  0.05\u001B[39m\u001B[49m\u001B[0m, train_loss=\u001B[34m 9.6696\u001B[39m\u001B[49m\u001B[0m, learning_rate=\u001B[34m5.00e-04\u001B[39m\u001B[49m\u001B[0m\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n",
      "\u001B[38;2;0;186;142m2022-02-26 16:23:29\u001B[38;2;97;175;239m| \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[LMTTransformer training]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mon_log\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m194\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mstep=\u001B[34m  12\u001B[39m\u001B[49m\u001B[0m, epoch=\u001B[34m  0.05\u001B[39m\u001B[49m\u001B[0m, train_loss=\u001B[34m 9.5517\u001B[39m\u001B[49m\u001B[0m, learning_rate=\u001B[34m5.00e-04\u001B[39m\u001B[49m\u001B[0m\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n",
      "\u001B[38;2;0;186;142m2022-02-26 16:23:32\u001B[38;2;97;175;239m| \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[LMTTransformer training]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mon_log\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m194\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mstep=\u001B[34m  13\u001B[39m\u001B[49m\u001B[0m, epoch=\u001B[34m  0.06\u001B[39m\u001B[49m\u001B[0m, train_loss=\u001B[34m 9.5394\u001B[39m\u001B[49m\u001B[0m, learning_rate=\u001B[34m5.00e-04\u001B[39m\u001B[49m\u001B[0m\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n",
      "\u001B[38;2;0;186;142m2022-02-26 16:23:35\u001B[38;2;97;175;239m| \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[LMTTransformer training]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mon_log\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m194\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mstep=\u001B[34m  14\u001B[39m\u001B[49m\u001B[0m, epoch=\u001B[34m  0.06\u001B[39m\u001B[49m\u001B[0m, train_loss=\u001B[34m 9.5139\u001B[39m\u001B[49m\u001B[0m, learning_rate=\u001B[34m5.00e-04\u001B[39m\u001B[49m\u001B[0m\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n",
      "\u001B[38;2;0;186;142m2022-02-26 16:23:38\u001B[38;2;97;175;239m| \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[LMTTransformer training]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mon_log\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m194\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mstep=\u001B[34m  15\u001B[39m\u001B[49m\u001B[0m, epoch=\u001B[34m  0.07\u001B[39m\u001B[49m\u001B[0m, train_loss=\u001B[34m 9.4051\u001B[39m\u001B[49m\u001B[0m, learning_rate=\u001B[34m5.00e-04\u001B[39m\u001B[49m\u001B[0m\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/76/fm8fgr4n1p78whqg7x_bd5480000gn/T/ipykernel_9350/1155184133.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moutput_dir\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/transformers/trainer.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1363\u001B[0m                         \u001B[0mtr_loss_step\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1364\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1365\u001B[0;31m                     \u001B[0mtr_loss_step\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1366\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1367\u001B[0m                 if (\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/transformers/trainer.py\u001B[0m in \u001B[0;36mtraining_step\u001B[0;34m(self, model, inputs)\u001B[0m\n\u001B[1;32m   1938\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1939\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautocast_smart_context_manager\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1940\u001B[0;31m             \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompute_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1941\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1942\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mn_gpu\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/UMich/Research/Music with NLP/Symbolic-Music-Generation/musicnlp/util/train.py\u001B[0m in \u001B[0;36mcompute_loss\u001B[0;34m(self, model, inputs, return_outputs)\u001B[0m\n\u001B[1;32m     47\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     48\u001B[0m             \u001B[0mlabels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 49\u001B[0;31m         \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     50\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m         \u001B[0;31m# ========================== Begin of added ==========================\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/UMich/Research/Music with NLP/Symbolic-Music-Generation/musicnlp/model/long_music_transformer.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input_ids, mems, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    107\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"You have to specify either input_ids or inputs_embeds\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    108\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 109\u001B[0;31m         transformer_outputs = self.transformer(\n\u001B[0m\u001B[1;32m    110\u001B[0m             \u001B[0minput_ids\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    111\u001B[0m             \u001B[0mmems\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmems\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/transformers/models/transfo_xl/modeling_transfo_xl.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input_ids, mems, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    959\u001B[0m                 \u001B[0mhids\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcore_out\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    960\u001B[0m                 \u001B[0mmems_i\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mmems\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mmems\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 961\u001B[0;31m                 layer_outputs = layer(\n\u001B[0m\u001B[1;32m    962\u001B[0m                     \u001B[0mcore_out\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    963\u001B[0m                     \u001B[0mpos_emb\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/transformers/models/transfo_xl/modeling_transfo_xl.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, dec_inp, r, dec_attn_mask, mems, head_mask, output_attentions)\u001B[0m\n\u001B[1;32m    387\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdec_inp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdec_attn_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmems\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhead_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutput_attentions\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    388\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 389\u001B[0;31m         attn_outputs = self.dec_attn(\n\u001B[0m\u001B[1;32m    390\u001B[0m             \u001B[0mdec_inp\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    391\u001B[0m             \u001B[0mr\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/transformers/models/transfo_xl/modeling_transfo_xl.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, w, r, attn_mask, mems, head_mask, output_attentions)\u001B[0m\n\u001B[1;32m    317\u001B[0m         \u001B[0;31m# compute attention score\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    318\u001B[0m         \u001B[0mrw_head_q\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mw_head_q\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mr_w_bias\u001B[0m  \u001B[0;31m# qlen x bsz x n_head x d_head\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 319\u001B[0;31m         \u001B[0mAC\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meinsum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"ibnd,jbnd->ijbn\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mrw_head_q\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mw_head_k\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# qlen x klen x bsz x n_head\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    320\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    321\u001B[0m         \u001B[0mrr_head_q\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mw_head_q\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mr_r_bias\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/torch/functional.py\u001B[0m in \u001B[0;36meinsum\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m    323\u001B[0m         \u001B[0;31m# recurse incase operands contains value that has torch function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    324\u001B[0m         \u001B[0;31m# in the original implementation this line is omitted\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 325\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0meinsum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mequation\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0m_operands\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    326\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    327\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0m_VF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meinsum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mequation\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moperands\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[attr-defined]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/torch/functional.py\u001B[0m in \u001B[0;36meinsum\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m    325\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0meinsum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mequation\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0m_operands\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    326\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 327\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_VF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meinsum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mequation\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moperands\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[attr-defined]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    328\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    329\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(trainer.args.output_dir)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}