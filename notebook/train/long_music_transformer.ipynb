{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Train Music Transformer\n",
    "Since Fri. Feb. 25th, 2022\n",
    "\n",
    "Set up training in colab\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "\n",
    "### Ipython\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Colab\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/stefanh/Documents/UMich/Research/Music with NLP\n",
      "Symbolic-Music-Generation\n",
      "musicnlp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    ! pip3 install sty icecream transformers datasets\n",
    "\n",
    "    sys.path.append(os.path.join('drive', 'My Drive', 'Research', 'Zeroshot Text Classification', 'Zeroshot-Text-Classification'))\n",
    "\n",
    "\n",
    "from musicnlp.util import *\n",
    "\n",
    "\n",
    "print(PATH_BASE)\n",
    "print(DIR_PROJ)\n",
    "print(PKG_NM)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "from icecream import ic\n",
    "\n",
    "from musicnlp.util import *\n",
    "from musicnlp.model import long_music_transformer as lmt\n",
    "\n",
    "\n",
    "seed = config('random-seed')\n",
    "transformers.set_seed(seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prep for training\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/hf_datasets/musicnlp music extraction, dnm=POP909, n=909, mode=melody, 2022-02-25 20-59-06/cache-f417996c5f50becf.arrow\n",
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/hf_datasets/musicnlp music extraction, dnm=POP909, n=909, mode=melody, 2022-02-25 20-59-06/cache-bdad8eedf3d98cb4.arrow\n",
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/hf_datasets/musicnlp music extraction, dnm=POP909, n=909, mode=melody, 2022-02-25 20-59-06/cache-e6c3ee9dc9d05a25.arrow\n",
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/hf_datasets/musicnlp music extraction, dnm=POP909, n=909, mode=melody, 2022-02-25 20-59-06/cache-47ffba45fbbacb63.arrow\n",
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/hf_datasets/musicnlp music extraction, dnm=POP909, n=909, mode=melody, 2022-02-25 20-59-06/cache-02a376952c146b6a.arrow\n",
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/hf_datasets/musicnlp music extraction, dnm=POP909, n=909, mode=melody, 2022-02-25 20-59-06/cache-001fcd44b318634e.arrow\n",
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/hf_datasets/musicnlp music extraction, dnm=POP909, n=909, mode=melody, 2022-02-25 20-59-06/cache-d1d88773687384b1.arrow\n",
      "Loading cached processed dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/hf_datasets/musicnlp music extraction, dnm=POP909, n=909, mode=melody, 2022-02-25 20-59-06/cache-321410a59e6d8d2a.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/stefanh/Documents/UMich/Research/Music with NLP/datasets/MNLP-Combined/hf_datasets/musicnlp music extraction, dnm=POP909, n=909, mode=melody, 2022-02-25 20-59-06/cache-655330db17738fe9.arrow\n",
      "ic| trainer.args.output_dir: ('/Users/stefanh/Documents/UMich/Research/Music with '\n",
      "                              'NLP/Symbolic-Music-Generation/models/debug/2022-02-26 15-06-59')\n"
     ]
    },
    {
     "data": {
      "text/plain": "'/Users/stefanh/Documents/UMich/Research/Music with NLP/Symbolic-Music-Generation/models/debug/2022-02-26 15-06-59'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fnm = 'musicnlp music extraction, dnm=POP909, n=909, mode=melody, 2022-02-22 19-00-40'\n",
    "fnm = 'musicnlp music extraction, dnm=POP909, n=909, mode=melody, 2022-02-25 20-59-06'\n",
    "\n",
    "\n",
    "md_nm = 'debug'\n",
    "# md_nm = 'debug-large'\n",
    "n = None\n",
    "mdl, tokenizer, dset_tr, trainer = lmt.get_all_setup(model_name=md_nm, dataset_name=fnm, n_sample=n, random_seed=seed)\n",
    "ic(trainer.args.output_dir)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;2;0;186;142m2022-02-26 15:06:59\u001B[38;2;97;175;239m| \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[LMTTransformer training]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mon_train_begin\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m47\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mTraining started with \u001B[35m{\u001B[39m\u001B[49m\u001B[0m#data: \u001B[34m909\u001B[39m\u001B[49m\u001B[0m, model size: \u001B[34m8\u001B[39m\u001B[49m\u001B[0m, learning rate: \u001B[34m5e-05\u001B[39m\u001B[49m\u001B[0m, batch shape: \u001B[34m(4, 8)\u001B[39m\u001B[49m\u001B[0m, #epochs: \u001B[34m1\u001B[39m\u001B[49m\u001B[0m, #steps: \u001B[34m227\u001B[39m\u001B[49m\u001B[0m\u001B[35m}\u001B[39m\u001B[49m\u001B[0m\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/76/fm8fgr4n1p78whqg7x_bd5480000gn/T/ipykernel_9350/1155184133.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moutput_dir\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/transformers/trainer.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1363\u001B[0m                         \u001B[0mtr_loss_step\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1364\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1365\u001B[0;31m                     \u001B[0mtr_loss_step\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1366\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1367\u001B[0m                 if (\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/transformers/trainer.py\u001B[0m in \u001B[0;36mtraining_step\u001B[0;34m(self, model, inputs)\u001B[0m\n\u001B[1;32m   1956\u001B[0m             \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdeepspeed\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1957\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1958\u001B[0;31m             \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1959\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1960\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdetach\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/torch/_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    305\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    306\u001B[0m                 inputs=inputs)\n\u001B[0;32m--> 307\u001B[0;31m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    308\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    309\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/music-nlp/lib/python3.9/site-packages/torch/autograd/__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    152\u001B[0m         \u001B[0mretain_graph\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    153\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 154\u001B[0;31m     Variable._execution_engine.run_backward(\n\u001B[0m\u001B[1;32m    155\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    156\u001B[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(trainer.args.output_dir)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}